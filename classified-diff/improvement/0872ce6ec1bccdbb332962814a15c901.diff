DIR d3f5c7e2afad9ce0d76640075cd1b192
--- 20070520-1.c.{atmega128}.{2}.{vanilla}.s	2020-08-07 14:51:54.652776961 +0000
+++ 20070520-1.c.{atmega128}.{2}.{ccmode}.s	2020-08-07 14:51:55.156781101 +0000
@@ -27,84 +27,65 @@
 	push r17
 	push r28
 	push r29
-	rcall .
-	rcall .
-	in r28,__SP_L__
-	in r29,__SP_H__
 /* prologue: function */
-/* frame size = 4 */
-/* stack size = 22 */
-.L__stack_usage = 22
+/* frame size = 0 */
+/* stack size = 18 */
+.L__stack_usage = 18
 	movw r30,r24
 	movw r24,r22
-	movw r18,r30
-	sub r18,r22
-	sbc r19,r23
+	movw r28,r30
+	sub r28,r22
+	sbc r29,r23
+	movw r18,r28
 	subi r18,-3
 	sbci r19,-1
-	movw r14,r18
-	movw r2,r22
-	lsl r2
-	rol r3
-	lsl r2
-	rol r3
-	movw r26,r2
+	movw r2,r18
+	movw r26,r22
+	lsl r26
+	rol r27
+	lsl r26
+	rol r27
 	sbiw r26,1
-	movw r20,r26
-	add r20,r30
-	adc r21,r31
-	std Y+4,r21
-	std Y+3,r20
+	add r26,r30
+	adc r27,r31
 	movw r18,r22
 	lsl r18
 	rol r19
-	movw r4,r20
+	movw r4,r26
 	sub r4,r18
 	sbc r5,r19
-	movw r26,r14
-	adiw r26,1
-	ld r16,X
-	sbiw r26,1
-	ld r20,-X
-	movw r10,r26
+	movw r28,r2
+	ldd r16,Y+1
+	ld r20,-Y
+	movw r10,r28
 	sub r16,r20
 	sbc r17,r17
-	ldd r26,Y+3
-	ldd r27,Y+4
 	ld r22,X
-	movw r26,r4
-	ld r20,X
+	movw r28,r4
+	ld r20,Y
 	sub r22,r20
 	sbc r23,r23
 	clr r6
 	clr r7
 	sub r6,r24
 	sbc r7,r25
-	movw r18,r14
-	subi r18,-2
-	sbci r19,-1
-	std Y+2,r19
-	std Y+1,r18
+	ldi r29,2
+	add r2,r29
+	adc r3,__zero_reg__
 	movw r14,r4
 	ldi r18,lo8(2)
 	ldi r19,0
 .L2:
-	ldd r20,Y+3
-	ldd r21,Y+4
-	add r20,r24
-	adc r21,r25
-	std Y+4,r21
-	std Y+3,r20
+	add r26,r24
+	adc r27,r25
 	add r14,r6
 	adc r15,r7
-	ldd r26,Y+1
-	ldd r27,Y+2
-	ld r20,X+
-	std Y+2,r27
-	std Y+1,r26
-	movw r26,r10
-	ld r21,-X
-	movw r10,r26
+	movw r28,r2
+	ld r20,Y+
+	movw r2,r28
+	movw r28,r10
+	ld r21,-Y
+	movw r10,r28
 	sub r20,r21
 	sbc r21,r21
 	mul r20,r18
@@ -116,13 +97,11 @@
 	clr r1
 	add r16,r12
 	adc r17,r13
-	ldd r26,Y+3
-	ldd r27,Y+4
 	ld r20,X
 	mov r8,r20
 	mov r9,__zero_reg__
-	movw r26,r14
-	ld r20,X
+	movw r28,r14
+	ld r20,Y
 	movw r12,r8
 	sub r12,r20
 	sbc r13,__zero_reg__
@@ -177,24 +156,28 @@
 	asr r23
 	ror r22
 	movw r18,r24
-	sub r18,r2
-	sbc r19,r3
-	add r4,r18
-	adc r5,r19
-	movw r26,r4
-	adiw r26,8
-	ld r18,X
+	lsl r18
+	rol r19
+	lsl r18
+	rol r19
+	movw r26,r24
+	sub r26,r18
+	sbc r27,r19
+	add r4,r26
+	adc r5,r27
+	movw r28,r4
+	ldd r18,Y+8
 	add r8,r18
 	adc r9,__zero_reg__
-	ldi r27,-1
-	sub r8,r27
-	sbc r9,r27
+	ldi r29,-1
+	sub r8,r29
+	sbc r9,r29
 	swap r8
 	swap r9
-	ldi r27,0xf0
-	and r9,r27
+	ldi r28,0xf0
+	and r9,r28
 	eor r9,r8
-	and r8,r27
+	and r8,r28
 	eor r9,r8
 	movw r18,r20
 	add r18,r22
@@ -208,170 +191,153 @@
 	sbc r19,r27
 	add r8,r18
 	adc r9,r19
-	ldi r16,lo8(8)
-	mov r14,r16
-	mov r15,__zero_reg__
+	ldi r26,lo8(8)
+	ldi r27,0
 .L3:
-	movw r26,r8
-	asr r27
-	ror r26
-	asr r27
-	ror r26
-	asr r27
-	ror r26
-	asr r27
-	ror r26
-	asr r27
-	ror r26
-	movw r16,r26
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r18,X
+	movw r28,r8
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r18,Y
 	st Z,r18
 	movw r18,r20
 	add r18,r8
 	adc r19,r9
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+1,r17
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+1,r28
 	add r18,r20
 	adc r19,r21
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+2,r17
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+2,r28
 	add r18,r20
 	adc r19,r21
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+3,r17
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+3,r28
 	add r18,r20
 	adc r19,r21
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+4,r17
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+4,r28
 	add r18,r20
 	adc r19,r21
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+5,r17
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+5,r28
 	add r18,r20
 	adc r19,r21
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+6,r17
-	movw r16,r18
-	add r16,r20
-	adc r17,r21
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r18,X
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+6,r28
+	movw r28,r18
+	add r28,r20
+	adc r29,r21
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r18,Y
 	std Z+7,r18
 	add r30,r24
 	adc r31,r25
-	ldi r27,1
-	sub r14,r27
-	sbc r15,__zero_reg__
+	sbiw r26,1
 	add r8,r22
 	adc r9,r23
-	cp r14,__zero_reg__
-	cpc r15,__zero_reg__
+	sbiw r26,0
 	breq .+2
 	rjmp .L3
 /* epilogue start */
-	pop __tmp_reg__
-	pop __tmp_reg__
-	pop __tmp_reg__
-	pop __tmp_reg__
 	pop r29
 	pop r28
 	pop r17
