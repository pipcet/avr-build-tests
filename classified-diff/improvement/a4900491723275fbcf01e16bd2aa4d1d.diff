DIR d3f5c7e2afad9ce0d76640075cd1b192
--- 20070520-1.c.{atmega128}.{3}.{vanilla}.s	2020-08-07 14:51:54.696777322 +0000
+++ 20070520-1.c.{atmega128}.{3}.{ccmode}.s	2020-08-07 14:51:55.336782580 +0000
@@ -9,8 +9,6 @@
 .global	ff_pred8x8_plane_c
 	.type	ff_pred8x8_plane_c, @function
 ff_pred8x8_plane_c:
-	push r4
-	push r5
 	push r6
 	push r7
 	push r8
@@ -27,123 +25,121 @@
 	push r29
 /* prologue: function */
 /* frame size = 0 */
-/* stack size = 16 */
-.L__stack_usage = 16
+/* stack size = 14 */
+.L__stack_usage = 14
 	movw r30,r24
 	movw r24,r22
 	movw r26,r30
 	sub r26,r22
 	sbc r27,r23
 	adiw r26,3
-	movw r12,r22
-	lsl r12
-	rol r13
-	lsl r12
-	rol r13
-	movw r28,r12
+	movw r28,r22
+	lsl r28
+	rol r29
+	lsl r28
+	rol r29
 	sbiw r28,1
-	movw r6,r28
-	add r6,r30
-	adc r7,r31
+	movw r8,r28
+	add r8,r30
+	adc r9,r31
 	movw r18,r22
 	lsl r18
 	rol r19
-	movw r20,r6
-	sub r20,r18
-	sbc r21,r19
+	movw r22,r8
+	sub r22,r18
+	sbc r23,r19
 	adiw r26,1
-	ld r16,X
+	ld r12,X
 	sbiw r26,1
 	movw r18,r26
 	subi r18,1
 	sbc r19,__zero_reg__
 	movw r28,r18
 	ld r18,Y
-	sub r16,r18
-	sbc r17,r17
-	movw r28,r6
-	ld r19,Y
-	movw r28,r20
+	sub r12,r18
+	sbc r13,r13
+	movw r28,r8
+	ld r14,Y
+	movw r28,r22
 	ld r18,Y
-	mov r22,r19
-	sub r22,r18
-	sbc r23,r23
-	movw r8,r22
-	clr r14
-	clr r15
-	sub r14,r24
-	sbc r15,r25
+	sub r14,r18
+	sbc r15,r15
+	clr r16
+	clr r17
+	sub r16,r24
+	sbc r17,r25
 	cpi r24,1
 	cpc r25,__zero_reg__
 	breq .+2
-	rjmp .L7
-	movw r18,r20
-	add r18,r14
-	adc r19,r15
+	rjmp .L8
+	movw r18,r22
+	add r18,r16
+	adc r19,r17
 	adiw r26,2
-	ld r22,X
+	ld r20,X
 	sbiw r26,2
 	movw r10,r26
 	ldi r29,2
 	sub r10,r29
 	sbc r11,__zero_reg__
 	movw r28,r10
-	ld r23,Y
-	sub r22,r23
-	sbc r23,r23
-	lsl r22
-	rol r23
-	movw r10,r22
-	add r10,r16
-	adc r11,r17
-	movw r28,r6
-	ldd r22,Y+1
-	movw r28,r18
-	ld r23,Y
-	sub r22,r23
-	sbc r23,r23
-	lsl r22
-	rol r23
-	add r8,r22
-	adc r9,r23
-	add r18,r14
-	adc r19,r15
+	ld r21,Y
+	sub r20,r21
+	sbc r21,r21
+	lsl r20
+	rol r21
+	add r20,r12
+	adc r21,r13
+	movw r28,r8
+	ldd r12,Y+1
+	movw r28,r18
+	ld r13,Y
+	sub r12,r13
+	sbc r13,r13
+	lsl r12
+	rol r13
+	movw r10,r12
+	add r10,r14
+	adc r11,r15
+	add r18,r16
+	adc r19,r17
 	adiw r26,3
-	ld r22,X
+	ld r14,X
 	sbiw r26,3
-	movw r16,r26
-	subi r16,3
-	sbc r17,__zero_reg__
-	movw r28,r16
-	ld r23,Y
-	sub r22,r23
-	sbc r23,r23
-	movw r16,r22
-	lsl r16
-	rol r17
-	add r16,r22
-	adc r17,r23
-	add r10,r16
-	adc r11,r17
-	movw r28,r6
-	ldd r16,Y+2
-	movw r28,r18
-	ld r22,Y
-	sub r16,r22
-	sbc r17,r17
-	movw r22,r16
-	lsl r22
-	rol r23
-	add r22,r16
-	adc r23,r17
-	add r22,r8
-	adc r23,r9
+	movw r12,r26
+	ldi r29,3
+	sub r12,r29
+	sbc r13,__zero_reg__
+	movw r28,r12
+	ld r15,Y
+	sub r14,r15
+	sbc r15,r15
+	movw r12,r14
+	lsl r12
+	rol r13
+	add r12,r14
+	adc r13,r15
+	add r12,r20
+	adc r13,r21
+	movw r28,r8
+	ldd r14,Y+2
+	movw r28,r18
+	ld r20,Y
+	sub r14,r20
+	sbc r15,r15
+	movw r20,r14
+	lsl r20
+	rol r21
+	add r20,r14
+	adc r21,r15
+	add r20,r10
+	adc r21,r11
 	adiw r26,4
-	ld r9,X
+	ld r15,X
 	sbiw r26,4
 	sbiw r26,4
 	ld r26,X
-	mov r28,r9
+	mov r28,r15
 	sub r28,r26
 	sbc r29,r29
 	movw r26,r28
@@ -151,246 +147,242 @@
 	rol r27
 	lsl r26
 	rol r27
-	movw r8,r26
-	add r8,r10
-	adc r9,r11
-	movw r26,r6
-	adiw r26,3
-	ld r28,X
-	mov r10,r28
-	mov r11,__zero_reg__
-	add r18,r14
-	adc r19,r15
+	add r26,r12
+	adc r27,r13
+	movw r28,r8
+	ldd r14,Y+3
+	mov r15,__zero_reg__
+	add r18,r16
+	adc r19,r17
 	movw r28,r18
+.L6:
 	ld r18,Y
-	movw r26,r10
-	sub r26,r18
-	sbc r27,__zero_reg__
-	movw r18,r26
+	movw r28,r14
+	sub r28,r18
+	sbc r29,__zero_reg__
+	movw r18,r28
 	lsl r18
 	rol r19
 	lsl r18
 	rol r19
-	add r18,r22
-	adc r19,r23
-.L3:
-	ldi r17,lo8(17)
-	mul r17,r8
-	movw r22,r0
-	mul r17,r9
-	add r23,r0
+	add r18,r20
+	adc r19,r21
+	ldi r28,lo8(17)
+	mul r28,r26
+	movw r20,r0
+	mul r28,r27
+	add r21,r0
 	clr __zero_reg__
-	subi r22,-16
-	sbci r23,-1
-	asr r23
-	ror r22
-	asr r23
-	ror r22
-	asr r23
-	ror r22
-	asr r23
-	ror r22
-	asr r23
-	ror r22
-	mul r17,r18
+	subi r20,-16
+	sbci r21,-1
+	asr r21
+	ror r20
+	asr r21
+	ror r20
+	asr r21
+	ror r20
+	asr r21
+	ror r20
+	asr r21
+	ror r20
+	mul r28,r18
 	movw r26,r0
-	mul r17,r19
+	mul r28,r19
 	add r27,r0
 	clr __zero_reg__
 	adiw r26,16
-	movw r14,r26
-	asr r15
-	ror r14
-	asr r15
-	ror r14
-	asr r15
-	ror r14
-	asr r15
-	ror r14
-	asr r15
-	ror r14
+	asr r27
+	ror r26
+	asr r27
+	ror r26
+	asr r27
+	ror r26
+	asr r27
+	ror r26
+	asr r27
+	ror r26
 	movw r18,r24
-	sub r18,r12
-	sbc r19,r13
-	add r20,r18
-	adc r21,r19
-	movw r28,r20
+	lsl r18
+	rol r19
+	lsl r18
+	rol r19
+	movw r28,r24
+	sub r28,r18
+	sbc r29,r19
+	add r22,r28
+	adc r23,r29
+	movw r28,r22
 	ldd r18,Y+8
-	movw r28,r10
-	add r28,r18
-	adc r29,__zero_reg__
-	adiw r28,1
-	swap r28
-	swap r29
-	andi r29,0xf0
-	eor r29,r28
-	andi r28,0xf0
-	eor r29,r28
-	movw r18,r22
+	add r14,r18
+	adc r15,__zero_reg__
+	ldi r29,-1
+	sub r14,r29
+	sbc r15,r29
+	swap r14
+	swap r15
+	ldi r18,0xf0
+	and r15,r18
+	eor r15,r14
+	and r14,r18
+	eor r15,r14
+	movw r18,r20
+	add r18,r26
+	adc r19,r27
+	movw r22,r18
+	lsl r22
+	rol r23
+	lsl r22
+	rol r23
+	sub r18,r22
+	sbc r19,r23
+	add r14,r18
+	adc r15,r19
+	ldi r22,lo8(8)
+	ldi r23,0
+.L4:
+	movw r28,r14
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r18,Y
+	st Z,r18
+	movw r18,r20
 	add r18,r14
 	adc r19,r15
-	movw r20,r18
-	lsl r20
-	rol r21
-	lsl r20
-	rol r21
-	sub r18,r20
-	sbc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+1,r28
+	add r18,r20
+	adc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+2,r28
+	add r18,r20
+	adc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+3,r28
+	add r18,r20
+	adc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+4,r28
+	add r18,r20
+	adc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+5,r28
+	add r18,r20
+	adc r19,r21
+	movw r28,r18
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r28,Y
+	std Z+6,r28
+	movw r28,r20
 	add r28,r18
 	adc r29,r19
-	ldi r20,lo8(8)
-	ldi r21,0
-.L4:
-	movw r18,r28
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	subi r18,lo8(-(ff_cropTbl+1024))
-	sbci r19,hi8(-(ff_cropTbl+1024))
-	movw r26,r18
-	ld r18,X
-	st Z,r18
-	movw r18,r22
-	add r18,r28
-	adc r19,r29
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+1,r17
-	add r18,r22
-	adc r19,r23
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+2,r17
-	add r18,r22
-	adc r19,r23
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+3,r17
-	add r18,r22
-	adc r19,r23
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+4,r17
-	add r18,r22
-	adc r19,r23
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+5,r17
-	add r18,r22
-	adc r19,r23
-	movw r16,r18
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	asr r17
-	ror r16
-	subi r16,lo8(-(ff_cropTbl+1024))
-	sbci r17,hi8(-(ff_cropTbl+1024))
-	movw r26,r16
-	ld r17,X
-	std Z+6,r17
-	add r18,r22
-	adc r19,r23
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	asr r19
-	ror r18
-	subi r18,lo8(-(ff_cropTbl+1024))
-	sbci r19,hi8(-(ff_cropTbl+1024))
-	movw r26,r18
-	ld r18,X
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	asr r29
+	ror r28
+	subi r28,lo8(-(ff_cropTbl+1024))
+	sbci r29,hi8(-(ff_cropTbl+1024))
+	ld r18,Y
 	std Z+7,r18
 	add r30,r24
 	adc r31,r25
-	subi r20,1
-	sbc r21,__zero_reg__
-	add r28,r14
-	adc r29,r15
-	cp r20,__zero_reg__
-	cpc r21,__zero_reg__
+	subi r22,1
+	sbc r23,__zero_reg__
+	add r14,r26
+	adc r15,r27
+	cp r22,__zero_reg__
+	cpc r23,__zero_reg__
 	breq .+2
 	rjmp .L4
 /* epilogue start */
@@ -408,82 +400,82 @@
 	pop r8
 	pop r7
 	pop r6
-	pop r5
-	pop r4
 	ret
-.L7:
-	movw r4,r6
-	add r4,r24
-	adc r5,r25
-	movw r10,r20
-	add r10,r14
-	adc r11,r15
+.L8:
+	movw r18,r8
+	add r18,r24
+	adc r19,r25
+	movw r8,r22
+	add r8,r16
+	adc r9,r17
 	adiw r26,2
-	ld r18,X
+	ld r20,X
 	sbiw r26,2
-	movw r22,r26
-	subi r22,2
-	sbc r23,__zero_reg__
-	movw r28,r22
-	ld r19,Y
-	sub r18,r19
-	sbc r19,r19
-	lsl r18
-	rol r19
-	movw r6,r18
-	add r6,r16
-	adc r7,r17
-	movw r28,r4
-	ld r18,Y
+	movw r10,r26
+	ldi r29,2
+	sub r10,r29
+	sbc r11,__zero_reg__
 	movw r28,r10
-	ld r19,Y
-	sub r18,r19
-	sbc r19,r19
-	lsl r18
-	rol r19
-	add r8,r18
-	adc r9,r19
-	add r4,r24
-	adc r5,r25
-	movw r18,r10
-	add r18,r14
-	adc r19,r15
+	ld r21,Y
+	sub r20,r21
+	sbc r21,r21
+	lsl r20
+	rol r21
+	movw r6,r20
+	add r6,r12
+	adc r7,r13
+	movw r28,r18
+	ld r12,Y
+	movw r28,r8
+	ld r13,Y
+	sub r12,r13
+	sbc r13,r13
+	lsl r12
+	rol r13
+	movw r10,r12
+	add r10,r14
+	adc r11,r15
+	add r18,r24
+	adc r19,r25
+	add r8,r16
+	adc r9,r17
 	adiw r26,3
-	ld r22,X
+	ld r14,X
 	sbiw r26,3
-	movw r16,r26
-	subi r16,3
-	sbc r17,__zero_reg__
-	movw r28,r16
-	ld r23,Y
-	sub r22,r23
-	sbc r23,r23
-	movw r16,r22
-	lsl r16
-	rol r17
-	add r16,r22
-	adc r17,r23
-	add r6,r16
-	adc r7,r17
-	movw r28,r4
-	ld r22,Y
-	movw r28,r18
-	ld r23,Y
-	sub r22,r23
-	sbc r23,r23
-	movw r16,r22
-	lsl r16
-	rol r17
-	add r22,r16
-	adc r23,r17
-	add r22,r8
-	adc r23,r9
+	movw r12,r26
+	ldi r29,3
+	sub r12,r29
+	sbc r13,__zero_reg__
+	movw r28,r12
+	ld r15,Y
+	sub r14,r15
+	sbc r15,r15
+	movw r12,r14
+	lsl r12
+	rol r13
+	add r12,r14
+	adc r13,r15
+	add r12,r6
+	adc r13,r7
+	movw r28,r18
+	ld r14,Y
+	movw r28,r8
+	ld r20,Y
+	sub r14,r20
+	sbc r15,r15
+	movw r20,r14
+	lsl r20
+	rol r21
+	add r20,r14
+	adc r21,r15
+	add r20,r10
+	adc r21,r11
 	adiw r26,4
-	ld r9,X
+	ld r15,X
 	sbiw r26,4
 	sbiw r26,4
 	ld r26,X
-	mov r28,r9
+	mov r28,r15
 	sub r28,r26
 	sbc r29,r29
 	movw r26,r28
@@ -491,29 +483,16 @@
 	rol r27
 	lsl r26
 	rol r27
-	movw r8,r26
-	add r8,r6
-	adc r9,r7
-	movw r28,r4
-	add r28,r24
-	adc r29,r25
-	ld r28,Y
-	mov r10,r28
-	mov r11,__zero_reg__
-	add r18,r14
-	adc r19,r15
-	movw r26,r18
-	ld r18,X
-	movw r28,r10
-	sub r28,r18
-	sbc r29,__zero_reg__
-	movw r18,r28
-	lsl r18
-	rol r19
-	lsl r18
-	rol r19
-	add r18,r22
-	adc r19,r23
-	rjmp .L3
+	add r26,r12
+	adc r27,r13
+	add r18,r24
+	adc r19,r25
+	movw r28,r18
+	ld r14,Y
+	mov r15,__zero_reg__
+	movw r28,r8
+	add r28,r16
+	adc r29,r17
+	rjmp .L6
 	.size	ff_pred8x8_plane_c, .-ff_pred8x8_plane_c
-	.ident	"GCC: (GNU) 11.0.0 20200802 (experimental)"
+	.ident	"GCC: (GNU) 11.0.0 20200804 (experimental)"
